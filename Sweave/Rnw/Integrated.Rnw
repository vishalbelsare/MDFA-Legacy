%\SweaveOpts{concordance=FALSE}

\chapter{Multivariate Direct Filter Analysis for Co-integrated Processes}
\label{chap:coint}

Chapter \ref{chap:int} provided the basic treatment of MDFA for non-stationary
 processes, but here we make an extension to treat co-integrated processes.
 This results in a change in the types of constraints that are enforced
  at signal frequencies.  Section \ref{sec:coint-zero} develops the simplest such
  case, where there is trend (or classic) co-integration, whereas Section
  \ref{sec:coint-gen} gives the general treatment.
 
\section{Co-integration at Frequency Zero} 
 \label{sec:coint-zero}

HERE Marc's material, VAR(1) coint example

HERE examples from paper Petrol and Ndc revisted with coint constraints

\section{A General Treatment of Co-integration}
\label{sec:coint-gen}
 
The general treatment of co-integration is complicated when 
  multiple unit roots are present.
For example, if there are trend and seasonal roots present, 
 application of a co-integrating vector to
the data process may only reduce the order of non-stationarity somewhat,
 rather than making the series stationary;
  this is unlike the simple case considered in the first section of the chapter.
  We first illustrate this point through the case of 
 dynamic factor component models.  
 
\begin{Illustration} {\bf Latent Dynamic Factor Processes.} \rm
\label{ill:dyn-fact}
 Consider a non-stationary process with differencing polynomial 
 $\delta (z) = \prod_{\ell=1}^p {(1 - e^{i \omega_{\ell}} z )}^{q_{\ell}}$, 
 where $q_{\ell}$ is the  multiplicity of each unit root at 
  frequency $\omega_{\ell}$.  When $\omega_{\ell}$ is not $0$ or $\pi$,
 a conjugate factor must appear in $\delta (z)$.  
  By a convenient abuse of notation, we denote
the pairing of such conjugate factors by ${(1 - e^{i \omega_{\ell} } z)}^{q_{\ell}}$, 
  with the understanding that
 $q_{\ell} $ is even and denotes the product of conjugate factors.

Suppose that the data process can be written as the sum of
 non-stationary latent processes, each of which has differencing
 polynomial ${(1 - e^{i \omega_{\ell}} z )}^{q_{\ell}}$, plus a
 residual stationary process.  We write this as
\begin{equation}
 \label{eq:chapnstat_structural}
 X_t = \sum_{\ell=1}^p S^{(\ell)}_t + S^{(0)}_t,
\end{equation}
 where ${(1 - e^{i \omega_{\ell}} L )}^{q_{\ell}} S^{(\ell)}_t$ is
 stationary for each $1 \leq \ell \leq p$, and $S^{(0)}_t$ is
 stationary as well.  Let the
 reduced polynomials $\delta^{(\ell)} (z) = \delta (z) \, {(1 -
 e^{i \omega_{\ell}} z )}^{-q_{\ell}}$ be defined.  Then applying
 $\delta (L)$ to the structural equation (\ref{eq:chapnstat_structural}) yields
\[
 \partial X_t   = \sum_{\ell=1}^p \, \delta^{(\ell)} (L) \partial
 S^{(\ell)}_t + \delta (L) S^{(0)}_t.
\]
   Each stationary latent process $\partial S^{(\ell)}_t$ may have
  singularities in its spectral density matrix, such that it can be
  represented as $\Lambda^{(\ell)}$ times some $C^{(\ell)}_t$, a
 stationary process of reduced dimension with spectral density
 matrix invertible at all frequencies.  Such a latent process is
 governed by a dynamic factor model (DFM), with $\Lambda^{(\ell)} =
 1_n$ recovering the general case.  We actually require
 $\Lambda^{(0)} = 1_n$ in order to guarantee that the spectrum of
 $\{ \partial X_t \}$ is non-singular except at a finite number of
 frequencies.

 Suppose that $\beta$ is a vector such that $\beta^{\prime}
 \Lambda^{(k)} = 0$ for some $1 \leq k \leq p$.  Then
\[
 \beta^{\prime} \, \partial X_t = \sum_{\ell \neq k} \,
 \beta^{\prime} \Lambda^{(\ell)} \, \delta^{(\ell)} (L)
 C^{(\ell)}_t + \beta^{\prime} \delta (L) S^{(0)}_t,
\]
 and note that ${(1 - e^{i \omega_{k}} L )}^{q_{k}}$ can be factored
 out of all terms on the right hand side.  Hence $\beta^{\prime}
 X_t$ only requires $\delta^{(k)} (L)$ differencing to become
 stationary; the frequency $\omega_k$ co-integrating vector $\beta$
 reduces the order of non-stationarity by the factor
 ${(1 - e^{i \omega_{k}} L )}^{q_{k}}$.  Moreover, if $\beta$ is in the left null space of
 several factor loadings $\Lambda^{(\ell)}$, the order of
 non-stationarity can be reduced further.  In an extreme case,
 $\beta^{\prime} \Lambda^{(\ell)} = 0$ for $1 \leq \ell \leq p$, so
 that $\beta^{\prime} X_t$ is stationary; however, whether or not
 the factor loadings have a non-trivial intersection of left null
 space depends on each process.
\end{Illustration}

 We now proceed with a general treatment of co-integrated  non-stationary
 processes, generalizing the basic non-stationary case discussed
  in  Chapter \ref{chap:int}.  Suppose that we left multiply 
 (\ref{eq:nonstat.rep-basis})  by $\beta^{\prime}$,
 which is a co-integrating vector at frequency $\omega_{j}$,
  and take $\mu = 0$ for simplicity; then we obtain
\begin{equation}
 \label{eq:co-intRep}
  \beta^{\prime} X_t = \sum_{k=1}^d \phi_k (t) p^{(k)} (L) \, \beta^{\prime} \, X_{0} 
   + \int_{-\pi}^{\pi}
 \frac{ e^{i \omega t} - \sum_{k=1}^d \phi_k (t) \, p^{(k)} 
  ( e^{-i \omega } )}{ \delta (e^{-i \omega}) } \; \beta^{\prime} \,  \ZZ
 (d\omega).
\end{equation}
  From our previous discussion, we know that this result should be a non-stationary
 process with differencing operator $\delta^{(j)} (z)$; this implies
 that there should be a cancellation of 
 $\beta^{\prime} \, d\ZZ (\omega)$ with the 
 ${(1 - e^{i \omega_{j}} e^{-i\omega} )}^{q_{j}}$ term in
 $\delta (e^{-i \omega})$.  As a result, we
 have the following spectral formalization of the co-integrating
 relation:
\begin{equation}
\label{eq:co-intRel}
 \beta^{\prime} \, \ZZ (d\omega) = 
 {(1 - e^{i \omega_{j}} e^{-i\omega} )}^{q_{j}} \, \ZZ^{(j)} (d\omega),
\end{equation}
 where $ \ZZ^{(j)} (\omega)$ is the orthogonal increments measure
 of another stationary invertible process.  This condition
 (\ref{eq:co-intRel}) is readily satisfied by the latent dynamic
 factor process discussed earlier, which is exemplary of the general
 situation of interest.  The extreme case, where the co-integrating
 vector lies in all the left null spaces of the component processes,
 allows us to factor $\delta (e^{-i \omega})$ completely from
 $\beta^{\prime}  \ZZ (d\omega)$, though such a property need not
 hold in practice.

In order to see the full effect of condition
 (\ref{eq:co-intRel}) on $\beta^{\prime} X_t$, we re-organize terms
 in equation (\ref{eq:co-intRep}).  Let us suppose, without loss of
 generality, that frequency $\omega_j$ has corresponding basis
 functions $\phi_1, \ldots, \phi_{q_j}$, so that the first $q_j$
 basis functions are annihilated by 
 ${(1 - e^{i \omega_j} L)}^{q_j}$.  Then we can write
\begin{align*}
 \beta^{\prime} X_t & = \sum_{k= q_j + 1}^d \phi_k (t) p^{(k)} (L) \, 
  \beta^{\prime} \, X_{0}
  + \int_{-\pi}^{\pi} \frac{ e^{i \omega t} - \sum_{k= q_j + 1}^d \phi_k (t) 
    \, p^{(k)} ( e^{-i \omega  } )}{ \delta^{(j)} (e^{-i \omega}) } \,  \ZZ^{(j)}
 (d\omega) \\
 & + \sum_{k=1}^{q_j} \phi_k (t) \,  \left(p^{(k)} (L)  
   \beta^{\prime} \,  X_0 - \int_{-\pi}^{\pi} \frac{ p^{(k)} (e^{-i \omega}) }{
 \delta^{(j)} (e^{-i \omega}) } \, \ZZ^{(j)} (d\omega) \right).
\end{align*}
 The first two terms are immediately recognized as the deterministic
 and stochastic portions respectively of a non-stationary process
 that has $\delta^{(j)} (z)$ for differencing operator.  The third
 term is left over, and consists of deterministic time series that
 are in the null space of ${(1 - e^{i \omega_j} L)}^{q_j}$.  
  To see this, observe that for the third term the expression in parentheses is
stochastic, but does not depend on time $t$, so that the resulting series is predictable.


Now $\delta^{(j)} (z)$  divides $p^{(k)} (z)$ for $1 \leq k \leq q_j$,
  and hence the stochastic portion of
 the third term is well-defined.   The
 coefficients of the $\phi_k (t)$ for $1 \leq k \leq q_j$ need not be
 zero, as counter-examples are easy to construct; consider two series that
 have a common stochastic trend with null vector $\beta^{\prime} =
 [1, \, 1]$, but whose underlying linear deterministic trends have
different slopes.  
%    In our analysis henceforth, we
% will assume that this third term is identically zero.
%
%  This is the general treatment of co-integration.  Now consider the
%  filter error $\epsilon_t = y_t - \widehat{y}_t$.  Let $\Delta(z) = \Gamma
%  (z) - \widehat{\Gamma} (z)$, so that
% \[
%  \epsilon_t = \sum_{j=1}^d \Delta(B) \phi_j (t) p^{(j)} (B) \, x_{0} + \int_{-\pi}^{\pi}
%  \frac{ e^{i \omega t} \, \Delta (e^{-i \omega})
%  - \sum_{j=1}^d \Delta (B) \phi_j (t) \, p^{(j)} ( e^{-i \omega
%  } )}{ \delta (e^{-i \omega}) } \; d \ZZ (\omega),
% \]
%  where $\Delta (B)$ acts only upon the basis functions $\phi_j (t)$.
%   In order to write this expression, we really need the common
%   differencing operators assumption.  Note that $\Delta (B) $ is a
%   row vector of filters, and it gets multiplied by the initial value
%   vectors and the orthogonal increments process $d\ZZ(\omega)$.
%   Clearly the error process is stationary if all the basis functions
%   are annihilated by $\Delta (B)$, because in that case we must be
%   able to factor $\Delta (B) = \tau (B) \delta (B)$ (where $\tau (B)$ is
%   a $1 \times m$ multivariate filter) and $\epsilon_t
%   = \int_{-\pi}^{\pi} e^{i \lambda t } \, \tau (e^{-i \lambda}) \,
%   d\ZZ (\lambda)$.  This is the case of full filter constraints,
%   analogous to the stationary case considered above.

% We next consider some natural properties of target and
% concurrent filters.  Let us first factor $\delta (B) = \delta^S (B)
% \delta^N (B)$ according to signal and noise unit roots.  We will
% henceforth suppose that $\delta^S (B) = {(1 - e^{i \omega k}
% B)}^{q_k}$ for some unit root $\zeta_k = e^{-i \omega k}$ of
% multiplicity $q_k$.  Thus $\delta^N (B) = \delta^{(k)} (B)$.  Both
% $\Gamma (B)$ and $\widehat{\Gamma} (B)$ should preserve signal basis functions,
% which are those $\phi_j (t)$ corresponding to the unit root
% $\zeta_k$.  In order to preserve all these functions (i.e., act as
% the identity filter on them all) when multiplicity $q_k$ is present,
% we must have that
% \[
%  \frac{ \Gamma (z) - \Gamma (\zeta_k) }{ {( z- \zeta_k)}^{q_k} }
%  \qquad  \frac{ \widehat{\Gamma} (z) - \widehat{\Gamma} (\zeta_k) }{ {( z- \zeta_k)}^{q_k} }
% \]
%  are both bounded in $z$.  Equivalently, the differences $\Gamma (z) - \Gamma (\zeta_k)$ and
% $  \widehat{\Gamma} (z) - \widehat{\Gamma} (\zeta_k)$ are each
%  divisible by $\delta^S (z)$.  We call this the {\it  signal preservation}
%  property of the filters.  For example, the signal extraction
%  filters described in McElroy and Trimbur (2012) always satisfy this
%  sort of condition.  In addition, because signal extraction filters
%  must eradicate all basis functions associated with noise
%  frequencies, it follows that $\delta^N (z)$ must be a factor of
%  $\Gamma (z) $ and $\widehat{\Gamma} (z)$.  We call this the {\it noise annihilation}
%  property of the filters.  Introduce the notation
% \[
%  \Gamma^{N,k} (z) = \Gamma (\zeta_k)  \delta^N (z) / \delta^N
%   (\zeta_k)  \qquad \widehat{\Gamma}^{N,k} =  \widehat{\Gamma} (\zeta_k)  \delta^N (z) / \delta^N
%   (\zeta_k).
% \]
%  Then we can write
% \begin{equation}
% \label{eq:deltaErrdecomp}
%  \Delta (z)  =
%   \left( \frac{ \Gamma (z) - \Gamma^{N,k} (z) }{ \delta (z) } \right) \; \delta (z)
%   - \left( \frac{ \widehat{\Gamma} (z) - \widehat{\Gamma}^{N,k} (z) }{ \delta (z) } \right) \; \delta (z)
%   + \left( \frac{ \Gamma (\zeta_k) - \widehat{\Gamma} (\zeta_k) }{ \delta^N
%   (\zeta_k) } \right) \; \delta^N (z).
% \end{equation}
%  We claim that the first two expressions involve a bounded rational function times
%  $\delta (z)$.  To see this true, observe that we only have to check
%  boundedness of $[ \Gamma (z) - \Gamma^{N,k} (z) ]/\delta (z)$ at $z$ values that are either roots of
%   $\delta^N (B)$ or $\delta^S (B)$ -- the same argument applies to
%   the second term involving $\widehat{\Gamma}$.  For a signal unit root, we
%   have $z = \zeta_k$, and boundedness follows from the signal
%   preservation property.  For a noise unit root, observe that we may
%   always factor $\delta^N (B)$ from $\Gamma (B)$ by the noise
%   annihilation property.  As for the third term of (\ref{eq:deltaErrdecomp}), it is
%   also always well-defined by the noise annihilation property.
% 
%   It is paramount that $\Delta (B)$ reduce the non-stationary
%   process to stationarity, and this can only happen in two ways:
%   first, a $\delta (B)$ can be factored out, which accomplishes the
%   requirement by differencing.  Second, the filter may have a linear
%   combination that is a co-integrating vector (associated with the
%   single signal frequency, which is important!), which together with
%   noise differencing accomplishes the requirement as well.  Note
%   that application of a co-integrating vector alone only removes
%   signal non-stationarity, and noise non-stationarity will remain.
%   The above decomposition for $\Delta (B)$ accomplishes this (under
%   the signal preservation and noise annihilation properties) if
%  \begin{equation}
%   \label{eq:co-intCond}
%  \frac{ \Gamma (\zeta_k) - \widehat{\Gamma} (\zeta_k) }{ \delta^N
%   (\zeta_k) } = \beta^{\prime}
%  \end{equation}
%   for some vector $\beta$ to be described.  If we impose that
%   $\beta$ is the zero vector, then we obtain the first case above,
%   where $\Delta (B)$ maintains stationarity by full differencing.
%   If instead we relax this to only imposing that $\beta = \beta_k$
%   be a co-integrating vector for the signal, then we obtain the
%   second case above.  Because there may be many choices for
%   $\beta_k$, depending on the co-integrating rank (the dimension of
%   the left null space of the factor loading matrix in the latent
%   dynamic factors formulation), this is a milder condition that may
%   allow for more flexibility in filter estimation.  Note that since
%   $\Gamma (\zeta_k) / \delta^N (\zeta_k)$ is a given quantity,
%   imposing (\ref{eq:co-intCond}) amounts to setting $\widehat{\Gamma}
%   (\zeta_k) / \delta^N (\zeta_k) = \beta^{\prime} + \Gamma (\zeta_k) /
%   \delta^N (\zeta_k)$ for a known co-integrating $\beta$.
% 
% We next develop the consequences of (\ref{eq:co-intCond}), where
%   $\beta$ is either zero or a signal co-integrating vector (the
%   second case will reduce to the first when we set $\beta = 0$ in
%   the following formulas).  Let $c_t = \delta^N (B) \beta^{\prime}
%   x_t$, which by our prior expression for $\beta^{\prime} x_t$ is
%   shown to be equal to $\int_{-\pi}^{\pi} e^{i \omega t} \; d
%   \ZZ^{(k)} (\omega)$.  The signal extraction error is
% \[
%  \epsilon_t  = \int_{-\pi}^{\pi} e^{i \omega t} \,
%   \left( \frac{ \Gamma (z) - \Gamma^{N,k} (z)   }{ \delta (z) } \right) \; d\ZZ (\omega)  - \int_{-\pi}^{\pi} e^{i \omega t} \,
%   \left( \frac{ \widehat{\Gamma} (z) - \widehat{\Gamma}^{N,k} (z) }{ \delta (z) } \right) \; d\ZZ (\omega)
%  + \int_{-\pi}^{\pi} e^{i \omega t} \; d  \ZZ^{(k)} (\omega).
% \]
%  Its variance involves a spectral density matrix that combines
%  information from the differenced series $\partial s_t$ as well as
%  the noise-differenced co-integrated series $c_t$.  We now suppose
%  that the joint spectral density matrix of these series is available
%  to us, which is certainly possible in the case of latent dynamic
%  factor models.  Letting $h_c$, $h_{c \partial x}$, and $h_{\partial
%  x}$ denote the spectra and cross-spectra, we have the joint spectra
%  for ${[c_t, \partial x_t^{\prime}]}^{\prime}$ is
% \[
%  h(\omega) = \left[ \begin{array}{ll} h_c (\omega) & h_{\partial x
%  c} (\omega) \\ h_{c \partial x} (\omega) & h_{\partial x} (\omega)
%  \end{array} \right].
% \]
%   Then the signal extraction variance is ${(2\pi)}^{-1}$ times the
%   integral of
% \[
%  \left[ 1, - \left( \frac{ \Gamma (z) - \Gamma^{N,k} (z) }{ \delta (z) } \right) +
%    \left( \frac{ \widehat{\Gamma} (z) - \widehat{\Gamma}^{N,k} (z) }{ \delta (z) } \right)  \right] \; h (\omega) \;
%   { \left[ 1, - \left( \frac{ \Gamma (\overline{z}) - \overline{\Gamma^{N,k}} (\overline{z})  }{ \delta (\overline{z}) } \right) +
%  \left( \frac{ \widehat{ \Gamma} (\overline{z}) -
%   \overline{\widehat{\Gamma}^{N,k} } (\overline{z}) }{ \delta (\overline{z}) } \right)
%   \right] }^{\prime}.
%  \]
%  Substituting the periodogram for $h$ at this point will allow
%  empirical estimation, where we impose the co-integrating relations
%  on $\widehat{\Gamma}$ and then optimize.
% 
%  In the case that $\beta$ is the zero vector, we are merely imposing full filter constraints by (\ref{eq:co-intCond}), and the multivariate DFA (M-DFA) condition
%   can be simplified.  Introduce the notation
% \[
%     \Gamma^{\delta,k} (z) =  \frac{ \Gamma (z) - \Gamma^{N,k} (z) }{ \delta (z) } \qquad
%   \widehat{\Gamma}^{\delta, k} (z) =  \frac{ \widehat{\Gamma} (z) - \widehat{\Gamma}^{N,k} (z) }{ \delta (z) }.
% \]
%   Although the former quantity can be computed from a knowledge of the target filter and the goals of analysis, the latter quantity is obliquely related to the parameters of the proposed concurrent filter.  In terms of these quantities, the M-DFA MSE is
% \[
%  \langle   \left[   \Gamma^{\delta, k} (z) -  \widehat{\Gamma}^{\delta, k} (z)  \right]   \; h_{\partial x} \;
%   { \left[  \Gamma^{\delta, k} (\overline{z}) -  \widehat{\Gamma}^{\delta, k} (\overline{z})    \right] }^{\prime} \rangle.
% \]
%  The filter conditions can be rephrased in terms of coefficient constraints, as in the stationary case.


 
