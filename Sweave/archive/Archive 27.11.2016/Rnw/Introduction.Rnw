% Parallelized computation chapters customization and replication
% simanz<-100 chapters customization and replication
% Load all chapters

\chapter{Introduction}\label{intro_sec}

\section{Classic Model-Based Paradigm}

Marc's perspective:
\begin{itemize}
\item Maximum Likelihood, main purpose: determine DGP. If DGP is known then optimality can be invoked, in principle. 
\item Problem: model misspecification. Pseudo maximum likelihood: one-step ahead mean-square criterion. 
\item Emphasizes short-term performances, only (contrast with real-time trend extraction: long-term component). 
\item Rigid criterion: can account neither for relevant problem-structure (signal extraction=one and multi-step ahead forecasts) nor for various user-priorities (ATS-trilemma).
\end{itemize}

Tucker/Chris' perspectives:...


\section{A Shift of Perspective: Tackling the (Relevant) Problem-Structure and Addressing User-Priorities}

Refer to DFA and Trilemma papers with Tucker. Refer to chapters \ref{mse_sec} (problem structure) and \ref{ats_sec} (user-priorities). 

\section{Univariate DFA}

Refer to DFA-paper with Tucker and \href{http://blog.zhaw.ch/sef/files/2014/10/DFA.pdf}{DFA} (Sweave environment: replication). 


\section{This Book's Contribution: Multivariate (M-) DFA}

Problem structure (chapter \ref{mse_sec}); forecasting/nowcasting/backcasting and filter revisions (chapter \ref{fil_sec});filter constraints (chapter \ref{con_sec}); ATS-trilemma, customization and user-priorities (chapter \ref{ats_sec}); replicating and enhancing classical model-based approaches and HP/CF-filters (chapter \ref{rep_sec}); addressing more sophisticated gain/loss structures (chapter \ref{exo_sec}); developing inferential aspects (chapter \ref{inf_sec}); Regularization Troika and tackling overfitting (chapter \ref{reg_sec}); data-revisions (chapter \ref{rev_sec}); solving the mixed-frequency problem (chapter \ref{mix_sec}); extensions to non-stationary integrated (chapter \ref{int_sec}) and cointegrated processes (chapter \ref{coint_sec}); adaptive filtering (chapter \ref{ada_sec}).




\section{R-Code}

We here briefly review the main R-code files and provide support for installation.

\subsection{Getting Started: Setting the Paths}

In order to be executable, the R-code requires access to program, output and data folders:

<<label=init,echo=TRUE>>=
# Load packages
rm(list=ls())
library(tseries)
library(xts)
# UC-0 (Morley, Nelson, and Zivot, 2003)
library(dlm)
# load numDeriv package 
library(numDeriv)
# recession shading
library(tis)  
# Quandl
# Load required libraries
library(RCurl)    # For getURL() and curl handler / cookie / google login
library(stringr)  # For str_trim() to trip whitespace from strings
library(Quandl)
require (Quandl)

#????????????????????????
#Quandl.auth("yWbLG4aMd_UZAzCPyXe5")
Quandl.api_key("ivVdJGV57TXA1RX5jgvp")
# Parallel computing
#require(doParallel)
#cl <- makeCluster(7)
#registerDoParallel(cl)

# Specify hard-disk
disk_id<-"C"

# Set paths
path.main<-paste(disk_id,
      ":\\wia_desktop\\Projekte\\2016\\MDFA-Legacy\\Sweave\\",sep="")
# Path to DFA-code: R-files are cut-and-pasted from DFA-book 
path_DFA.pgm<-paste(path.main,"R\\I-DFA\\",sep="")
# Path to MDFA-code
path_MDFA.pgm<-paste(path.main,"R\\I-MDFA\\",sep="")
# Path to model-based functions
path_MBA.pgm<-paste(path.main,"R\\MBA\\",sep="")
# Path to Latex-folder: all pdfs generated by the R-code are filed there
path.out<-paste(path.main,"Latex\\",sep="")
# Path to data 
path.dat<-paste(path.main,"Data\\",sep="")
@
The (univariate) DFA-code is the same as in \href{http://blog.zhaw.ch/sef/files/2014/10/DFA.pdf}{DFA}: all  empirical examples are and will be fully compatible. 

\subsection{DFA}\label{dfa_intro}
We here briefly review the relevant \href{http://blog.zhaw.ch/sef/files/2014/10/DFA.pdf}{DFA}\footnote{Left-click to activate the hyperlink.}-pieces (anchoring). 

\subsubsection{DFT and Periodogram}

The Discrete Fourier Transform (DFT) and the periodogram are defined in \href{http://blog.zhaw.ch/sef/files/2014/10/DFA.pdf}{DFA}, sections 2.2 and 2.3. The following function is cut-and-pasted from section 2.3, p.35:

%\url{http://blog.zhaw.ch/idp/sefblog/index.php?/archives/259-Elements-of-Forecasting-and-Signal-Extraction.html}


<<dft,echo=TRUE>>=
per<-function(x,plot_T)
{
  len<-length(x)
  per<-0:(len/2)
  DFT<-per

  for (k in 0:(len/2))
  {
    cexp <- complex(arg=-(1:len)*2*pi*k/len)
    DFT[k+1]<-sum(cexp*x*sqrt(1/(2*pi*len)))
  }
  per<-abs(DFT)^2
  if (plot_T)
  {
    par(mfrow=c(2,1))
    plot(per,type="l",axes=F,xlab="Frequency",ylab="Periodogram",
    main="Periodogram")
    axis(1,at=1+0:6*len/12,labels=c("0","pi/6","2pi/6","3pi/6",
    "4pi/6","5pi/6","pi"))
    axis(2)
    box()
    plot(log(per),type="l",axes=F,xlab="Frequency",ylab="Log-periodogram",
    main="Log-periodogram")
    axis(1,at=1+0:6*len/12,labels=c("0","pi/6","2pi/6","3pi/6",
    "4pi/6","5pi/6","pi"))
    axis(2)
    box()
  }
  return(list(DFT=DFT,per=per))
}
@
This function will be generalized in the new multivariate setting.

\subsubsection{DFA: Mean-Square Perspective}

A simple MSE (Mean-Square Error) version of the DFA is proposed in \href{http://blog.zhaw.ch/sef/files/2014/10/DFA.pdf}{DFA}, section 4.1: 

<<dfa_ms,echo=TRUE>>=

# This function computes mean-square DFA-solutions
# L is the length of the MA filter,
# periodogram is the frequency weighting function in the DFA
# Gamma is the transferfunction of the symmetric filter (target) and
# Lag is the lag-parameter: Lag=0 implies real-time filtering, Lag=L/2
#     implies symmetric filter
# The function returns optimal coefficients as well as the transfer 
#     function of the optimized real-time filter
dfa_ms<-function(L,periodogram,Lag,Gamma)
{

  K<-length(periodogram)-1
  X<-exp(-1.i*Lag*pi*(0:(K))/(K))*rep(1,K+1)*sqrt(periodogram)
  X_y<-exp(-1.i*Lag*pi*(0:(K))/(K))*rep(1,K+1)
  for (l in 2:L)          #l<-L<-21
  {
    X<-cbind(X,(cos((l-1-Lag)*pi*(0:(K))/(K))+
    1.i*sin((l-1-Lag)*pi*(0:(K))/(K)))*sqrt(periodogram))
    X_y<-cbind(X_y,(cos((l-1-Lag)*pi*(0:(K))/(K))+
    1.i*sin((l-1-Lag)*pi*(0:(K))/(K))))
  }
  xtx<-t(Re(X))%*%Re(X)+t(Im(X))%*%Im(X)
# MA-Filtercoefficients
  b<-as.vector(solve(xtx)%*%(t(Re(X_y))%*%(Gamma*periodogram)))
# Transferfunction
  trffkt<-1:(K+1)
  trffkt[1]<-sum(b)
  for (k in 1:(K))#k<-1
  {
    trffkt[k+1]<-(b%*%exp(1.i*k*(0:(length(b)-1))*pi/(K)))
  }
  return(list(b=b,trffkt=trffkt))
}

@
This function is nested in MDFA and can be replicated perfectly, see section \ref{ex_rep_dfa}. 

\subsubsection{DFA: ATS-Trilemma and Customization}

A general DFA-function, called \emph{dfa\textunderscore analytic}, is proposed in \href{http://blog.zhaw.ch/sef/files/2014/10/DFA.pdf}{DFA}, section 4.3.5. Customization and the generic ATS-trilemma are presented in \href{http://blog.zhaw.ch/sef/files/2014/10/DFA.pdf}{DFA}, sections 4.3 and 5.  Since the generalized function is lengthier than the previous MSE-implementation we here abstain from editing the code. Instead, all DFA-functions (including DFT, periodogram and DFA-MSE) can be sourced by calling the R-file \emph{DFA\textunderscore code}
<<dfa_ms,echo=TRUE>>=
source(file=paste(path_DFA.pgm,"DFA_code.r",sep=""))
@

In particular, the head of $dfa\textunderscore analytic$ is
<<dfa_ms,echo=TRUE>>=
head(dfa_analytic)
@
The additional control parameters $lambda,eta$ allow navigation in the generic framework of the ATS-trilemma, see chapter \ref{ats_sec} and $i1,i2$ account for filter constraints, see chapter \ref{con_sec}. 



\subsection{MDFA}\label{mdfa_intro}

The R-code for MDFA is more sophisticated and correspondingly more complex and lengthy. As for the DFA-package, the MDFA-code can be sourced. We here briefly review the corresponding pieces.


\subsubsection{Data-Matrix}

All time series are collected in a data-\emph{matrix}, say \emph{X}, which is organized as follows: 
\begin{itemize}
\item the first column $X[,1]$ of $X$ always corresponds to the target series: the target series $X[,1]$ is the time series to be forecasted, nowcasted or backcasted.
\item Columns 2,3,... of $X$ are allocated to the explaining variables (more than one in a multivariate setting). If the target series is part of the set of explaining variables (it does not have to), then it must be assigned a specific column - by convention always the second one - in $X$ i.e. in this case the target series is contained twice: in the first column (target) and in the second column (explaining data).     
\end{itemize}
Example:
<<dfa_ms,echo=TRUE>>=
set.seed(1)
len<-100
target<-arima.sim(list(ar=0.9),n=len)
explaining_2<-target+rnorm(len)
explaining<-cbind(target,explaining_2)
x<-cbind(target,explaining)
dimnames(x)[[2]]<-c("target","explaining 1","explaining 2")
head(x)
@
In this case we assume a two-dimensional Signal Extraction (SE-) problem whereby the target series (first column) is part of the set of explaining variables. For a one-step ahead forecast problem we might consider lagging of the explaining variables
<<dfa_ms,echo=TRUE>>=
x<-cbind(x[,1],lag(x[,2:3],-1))
dimnames(x)[[2]]<-c("target","lagged explaining 1","lagged explaining 2")
head(x)
@
However, our frequency-domain approach in such a case will be more general and it will avoid introduction of undesirable NA's.


\subsubsection{DFT}

In contrast to the univariate case, which can rely on the periodogram only, the multivariate case requires the (complex) DFT in order to account for cross-sectional dependencies\footnote{The relative phase-shift(s) of the explaining time series import. In the univariate case the relative phase-shift vanishes since the target and the explaining series are identical.}). Also, we here extend the scope of the method in order to cover the mixed-frequency case, see chapter \ref{mix_sec}. Finally, we allow for the possibility of integrated processes, see chapter \ref{int_sec}. The additional flexibility requires specific code-extensions which are implemented in the new $DFT.r$ file:


<<dfa_ms,echo=TRUE>>=
source(file=paste(path_MDFA.pgm,"DFT.r",sep=""))
@

In order to illustrate some of the new features we briefly look at the main DFT-function called $spec\textunderscore comp$:
<<dfa_ms,echo=TRUE>>=
spec_comp
@
The inner loop runs across the columns of the data-matrix \emph{X} (see above for definition and conventions) and the DFTs are stored in a matrix called \emph{weight\textunderscore func} which is returned by the function. The matrix \emph{weight\textunderscore func} collects all DFTs: the target series is always in the first column whereas the DFTs of the explaining series are in columns 2,3,... The function \emph{periodogram\textunderscore bp}, called in the above loop, is slightly more general than the DFA-function \emph{periodogram}, proposed in the previous section. In particular it can handle various integration orders as well as seasonal peculiarities.  \\

\subsubsection{MDFA}

The complete MDFA-estimation routines can be sourced as follows:
<<dfa_ms,echo=TRUE>>=
source(file=paste(path_MDFA.pgm,"I-MDFA.r",sep=""))
@

Let us briefly describe the four functions in this file (details are left for later sections):
\begin{itemize}
\item \emph{spec\textunderscore mat\textunderscore comp}: this function organizes the DFT according to the matrix-notation to be introduced in section \ref{matrix_not}.
\item \emph{mat\textunderscore func}: this function provides all regularization features to be discussed in chapter \ref{reg_sec}.
\item \emph{mdfa\textunderscore analytic\textunderscore new}: this is the main estimation routine. It computes filter coefficients and diagnostic statistics, see chapters \ref{mse_sec} (classical MSE-criterion), \ref{fil_sec} (filter revisions and chained backcasting), \ref{con_sec} (filter constraints), \ref{ats_sec} (customization), \ref{rep_sec} (replication of classical forecast paradigm(s)), \ref{inf_sec} (inference), \ref{reg_sec} (regularization), \ref{rev_sec} (vintage data), \ref{mix_sec} (mixed-frequency approach) and \ref{int_sec}, \ref{coint_sec}, \ref{ada_sec} (non-stationarity). 
\item \emph{MS\textunderscore decomp\textunderscore total}: this function decomposes the MSE-norm into Accuracy, Timeliness and Smoothness error components (ATS-trilemma), see McElroy/Wildi (2012) and chapter \ref{ats_sec}. 
\end{itemize}

\subsection{Feeding and Controlling MDFA}\label{control_dfa}

\subsubsection{Generic Approach: Rich User-Interface}

MDFA is a generic forecast and signal extraction paradigm. Besides replicating classical time series approaches it allows for some unique features like customization and  general filter-regularization (Regularization Troika and general H0-shrinkage). Also, it allows for tackling data revisions, mixed-frequency problems and non-stationarity. Accordingly, the user-interface is more sophisticated than the precedent DFA-package. In order to illustrate the topic we here briefly look at the head of the main estimation routine:    

<<dfa_ms,echo=TRUE>>=
head(mdfa_analytic)
@
Besides straightforward entries, like the DFT (\emph{weight\textunderscore func}, see previous section), the filter-length ($L$), or the target specification \emph{Gamma} there are numerous additional control parameters: the relevance and the modus operandi of most of them will be discussed in this book. 


\subsubsection{Default-Settings}

For convenience, we store a so-called \emph{default-setting} of the parameters in a file called \emph{control\textunderscore default}. In order to do so we first need to define the data (initialize the DFT-matrix) and specify the filter-length:
<<dfa_ms,echo=TRUE>>=
weight_func<-matrix(1:6)
L<-2
@
Given these two entries (data and filter-length), the default-settings are as follows:
<<dfa_ms,echo=TRUE>>=
K<-nrow(weight_func)-1
lambda<-0
Lag<-0
eta<-0
i1<-F
i2<-F
weight_constraint<-rep(1/(ncol(weight_func)-1),ncol(weight_func)-1)
lambda_cross<-lambda_decay<-lambda_smooth<-0
lin_eta<-F
shift_constraint<-rep(0,ncol(weight_func)-1)
grand_mean<-F
b0_H0<-NULL
c_eta<-F
weights_only<-F
weight_structure<-c(0,0)
white_noise<-F
synchronicity<-F
lag_mat<-matrix(rep(0:(L-1),ncol(weight_func)-1),nrow=L)
@
This particular configuration will be used extensively in chapter \ref{mse_sec}: mean-square criterion (no customization), no regularization, unconstrained design, no a priori knowledge, nowcasting, common identical sampling frequency, no data-revisions. The default-settings can be obtained by sourcing the corresponding R-file

<<dfa_ms,echo=TRUE>>=
source(file=paste(path_MDFA.pgm,"control_default.r",sep=""))
@


